{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d039593b",
   "metadata": {},
   "source": [
    "# find_images_to_be_fixed\n",
    "\n",
    "Code was provided by the Voxel51 Docs AI in reponse to this prompt:\n",
    "\n",
    "**Write a python script which uses voxel51 to identify images which need re-annotating and writes a report which includes filepath and problems detected for each image.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4896a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = '/home/aubrey/Desktop/crb-damage-detection-models'\n",
    "DATASET_DIR = f'{ROOT_DIR}/datasets/CRB005'\n",
    "MODEL_DIR = f'{ROOT_DIR}/models/CRB005/weights/CRB005.pt'\n",
    "FO_DATASET = 'fo_test_dataset_2'\n",
    "OUTPUT_DIR = '/home/aubrey/Desktop/reannotation_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "799ad97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "from fiftyone import ViewField as F\n",
    "import json\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "801aff27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Subprocess ['/home/aubrey/Desktop/fifty_one/.venv/lib/python3.12/site-packages/fiftyone/db/bin/mongod', '--dbpath', '/home/aubrey/.fiftyone/var/lib/mongo', '--logpath', '/home/aubrey/.fiftyone/var/lib/mongo/log/mongo.log', '--port', '0', '--nounixsocket'] exited with error 62:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"t\":{\"$date\":\"2025-11-01T06:30:29.545Z\"},\"s\":\"I\",  \"c\":\"CONTROL\",  \"id\":20697,   \"ctx\":\"main\",\"msg\":\"Renamed existing log file\",\"attr\":{\"oldLogPath\":\"/home/aubrey/.fiftyone/var/lib/mongo/log/mongo.log\",\"newLogPath\":\"/home/aubrey/.fiftyone/var/lib/mongo/log/mongo.log.2025-11-01T06-30-29\"}}\n",
      "ERROR: fiftyone.core.service.DatabaseService failed to bind to port\n",
      "Retrying...\n",
      "Local FiftyOne datasets: ['fo_test_dataset', 'fo_test_dataset_2', 'quickstart']\n"
     ]
    }
   ],
   "source": [
    "def wake_mongo():\n",
    "\n",
    "    # List all local datasets by name\n",
    "\n",
    "    # Reports error 26 on first try, indicating a problem opening the Mongo database.\n",
    "    # The following hack runs the code a second time. Seems to work well.\n",
    "    # Note: A dataset can be deleted using fo.delete_dataset(\"dataset name\")\n",
    "    try:\n",
    "        dataset_list = fo.list_datasets()\n",
    "    except Exception as e:\n",
    "        print(f'ERROR: {e}')\n",
    "        print(\"Retrying...\")\n",
    "        dataset_list = fo.list_datasets()\n",
    "    print(f'Local FiftyOne datasets: {dataset_list}')\n",
    "    \n",
    "wake_mongo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10b2b9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:        fo_test_dataset_2\n",
      "Media type:  image\n",
      "Num samples: 151\n",
      "Persistent:  True\n",
      "Tags:        []\n",
      "Sample fields:\n",
      "    id:                fiftyone.core.fields.ObjectIdField\n",
      "    filepath:          fiftyone.core.fields.StringField\n",
      "    tags:              fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:          fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    created_at:        fiftyone.core.fields.DateTimeField\n",
      "    last_modified_at:  fiftyone.core.fields.DateTimeField\n",
      "    ground_truth:      fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    predictions:       fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    mistakenness:      fiftyone.core.fields.FloatField\n",
      "    possible_missing:  fiftyone.core.fields.IntField\n",
      "    possible_spurious: fiftyone.core.fields.IntField\n",
      "    eval_tp:           fiftyone.core.fields.IntField\n",
      "    eval_fp:           fiftyone.core.fields.IntField\n",
      "    eval_fn:           fiftyone.core.fields.IntField\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset (replace with your actual dataset)\n",
    "# dataset = foz.load_zoo_dataset(\"quickstart\")\n",
    "dataset = fo.load_dataset(FO_DATASET)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba7c651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating detections...\n",
      " 100% |█████████████████| 151/151 [977.7ms elapsed, 0s remaining, 158.3 samples/s]      \n",
      "Performing IoU sweep...\n",
      " 100% |█████████████████| 151/151 [660.4ms elapsed, 0s remaining, 228.7 samples/s]      \n",
      "Evaluating detections...\n",
      " 100% |█████████████████| 151/151 [1.1s elapsed, 0s remaining, 145.8 samples/s]         \n",
      "Computing mistakenness...\n",
      " 100% |█████████████████| 151/151 [961.3ms elapsed, 0s remaining, 160.7 samples/s]      \n",
      "Mistakenness computation complete\n",
      "Report generated with 45 samples needing review\n",
      "Report saved to: reannotation_report.json\n",
      "Tagged 45 samples with 'needs_reannotation' tag\n"
     ]
    }
   ],
   "source": [
    "# Ensure you have model predictions on your dataset\n",
    "# If not, apply a model first:\n",
    "# model = foz.load_zoo_model(\"your-model\")\n",
    "# dataset.apply_model(model, \"predictions\")\n",
    "\n",
    "# Evaluate detections to identify potential issues\n",
    "results = dataset.evaluate_detections(\n",
    "    \"predictions\",\n",
    "    gt_field=\"ground_truth\",\n",
    "    eval_key=\"eval\",\n",
    "    compute_mAP=True,\n",
    ")\n",
    "\n",
    "# Compute mistakenness to find annotation errors\n",
    "import fiftyone.brain as fob\n",
    "fob.compute_mistakenness(\n",
    "    dataset,\n",
    "    \"predictions\",\n",
    "    label_field=\"ground_truth\",\n",
    ")\n",
    "\n",
    "# Create a report list\n",
    "report = []\n",
    "\n",
    "# 1. Find high-confidence false positives (likely annotation errors)\n",
    "fp_view = dataset.filter_labels(\n",
    "    \"predictions\",\n",
    "    (F(\"confidence\") > 0.85) & (F(\"eval\") == \"fp\")\n",
    ")\n",
    "\n",
    "for sample in fp_view:\n",
    "    report.append({\n",
    "        \"filepath\": sample.filepath,\n",
    "        \"problems\": [\"High-confidence false positive - possible missing ground truth annotation\"],\n",
    "        \"sample_id\": sample.id\n",
    "    })\n",
    "\n",
    "# 2. Find samples with high mistakenness scores\n",
    "mistake_view = dataset.filter_labels(\"ground_truth\", F(\"mistakenness\") > 0.95)\n",
    "\n",
    "for sample in mistake_view:\n",
    "    report.append({\n",
    "        \"filepath\": sample.filepath,\n",
    "        \"problems\": [\"High mistakenness score - likely annotation error\"],\n",
    "        \"sample_id\": sample.id\n",
    "    })\n",
    "\n",
    "# 3. Find possible missing annotations\n",
    "missing_view = dataset.match(F(\"possible_missing\") > 0)\n",
    "\n",
    "for sample in missing_view:\n",
    "    report.append({\n",
    "        \"filepath\": sample.filepath,\n",
    "        \"problems\": [\"Possible missing annotations detected by model\"],\n",
    "        \"sample_id\": sample.id\n",
    "    })\n",
    "\n",
    "# 4. Find possible spurious annotations\n",
    "spurious_view = dataset.match(F(\"possible_spurious\") > 0)\n",
    "\n",
    "for sample in spurious_view:\n",
    "    report.append({\n",
    "        \"filepath\": sample.filepath,\n",
    "        \"problems\": [\"Possible spurious/incorrect annotations\"],\n",
    "        \"sample_id\": sample.id\n",
    "    })\n",
    "    \n",
    "print(f\"Found {len(report)} problems needing review\")\n",
    "print('Note that some samples (images) may have multiple problems.')\n",
    "\n",
    "# print(f\"Report generated with {len(report)} samples needing review\")\n",
    "# print(\"Report saved to: reannotation_report.json\")\n",
    "\n",
    "# # Tag samples in FiftyOne for easy filtering\n",
    "# sample_ids = [item[\"sample_id\"] for item in report]\n",
    "# view = dataset.select(sample_ids)\n",
    "# view.tag_samples(\"needs_reannotation\")\n",
    "\n",
    "# print(f\"Tagged {len(sample_ids)} samples with 'needs_reannotation' tag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a58a3f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855faed3",
   "metadata": {},
   "source": [
    "## Create a YOLO dataset which can be imported by the DigitalSreeni Image Annotator\n",
    "\n",
    "It looks like the image annotator imports only the train split of a YOLO dataset.\n",
    "\n",
    "So the following code puts flattens the dataset to just 2 data folders ('images' and 'labels').\n",
    "\n",
    "The split dataset needs to be reconstructed after reannotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe82b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a YOLO dataset of the problematic samples for reannotation\n",
    "\n",
    "for i in ['images', 'labels']:\n",
    "    for j in ['train', 'val']:\n",
    "        os.makedirs(f'{OUTPUT_DIR}/{i}/{j}', exist_ok=True)\n",
    "\n",
    "i = 0\n",
    "for image in report:\n",
    "    i += 1\n",
    "    image_filepath = image['filepath']\n",
    "    data_split = image_filepath.split('/')[-2]\n",
    "    label_filepath = image_filepath.replace('/images/', '/labels/').replace('.jpg', '.txt') \n",
    "    # print(i, data_split, image_filepath)\n",
    "    shutil.copy2(image_filepath, f'{OUTPUT_DIR}/images/{data_split}')\n",
    "    shutil.copy2(label_filepath, f'{OUTPUT_DIR}/labels/{data_split}')\n",
    "    \n",
    "# Add a YAML file\n",
    "s = f'''\n",
    "names:\n",
    "- healthy\n",
    "- damaged\n",
    "- dead\n",
    "- vcut\n",
    "path: {OUTPUT_DIR}\n",
    "train: images/train\n",
    "val: images/val\n",
    "'''\n",
    "with open(f'{OUTPUT_DIR}/dataset.yaml', 'w') as f:\n",
    "    f.write(s) \n",
    "    \n",
    "# Create \"problematic_images_report.csv\" and save it in OUTPUT_DIR\n",
    "def filepath2filename(filepath):\n",
    "    return filepath.split('/')[-1]\n",
    "\n",
    "def problems2problem_str(problems):\n",
    "    return ', '.join(problems)\n",
    "\n",
    "df = pd.DataFrame(report)\n",
    "df['filename'] = df['filepath'].apply(filepath2filename)\n",
    "df['problems_str'] = df['problems'].apply(problems2problem_str)\n",
    "df.drop(columns=['filepath', 'problems', 'sample_id'], inplace=True )\n",
    "df.sort_values(by=['filename', 'problems_str'], inplace=True)\n",
    "\n",
    "# Group by col1 and concatenate strings in col2 with commas\n",
    "new_df = df.groupby('filename')['problems_str'].apply(lambda x: '|'.join(x)).reset_index()\n",
    "\n",
    "new_df.to_csv(f'{OUTPUT_DIR}/problematic_images_report.csv', index=False)\n",
    "print(f\"Saved report to {OUTPUT_DIR}/problematic_images_report.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796c5ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISHED: reannotation dataset at /home/aubrey/Desktop/reannotation_dataset\n"
     ]
    }
   ],
   "source": [
    "print('Reannotation dataset is at {OUTPUT_DIR}')\n",
    "print('FINISHED')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc035397",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "- Launch digitalsreeni image annotator: `am_image_annotator.sh`\n",
    "- Import the new reannotation dataset \n",
    "- Fix problems identified in problematic_images_report.csv\n",
    "- Add new annotations to the old ones\n",
    "- Retrain"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fifty_one",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
